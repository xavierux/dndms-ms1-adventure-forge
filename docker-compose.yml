services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - dndms_network

  kafka:
    image: confluentinc/cp-kafka:7.0.1
    container_name: kafka
    ports:
      # Puerto 9092 del contenedor mapeado al 9092 de tu MÁQUINA HOST
      # Esto es para que tu aplicación MS1 corriendo en el HOST (no como contenedor aún) pueda conectarse.
      - "9092:9092"
      # El puerto 29092 NO se expone al host, es solo para comunicación INTERNA entre contenedores.
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      # Define los listeners INTERNOS del broker Kafka dentro de su contenedor:
      KAFKA_LISTENERS: PLAINTEXT_INTERNAL://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      # Define CÓMO se anuncian estos listeners a los clientes:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT_INTERNAL://kafka:29092,PLAINTEXT_HOST://localhost:9092
      # Mapea los nombres de los listeners a protocolos de seguridad:
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT_INTERNAL:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      # Para comunicación entre brokers en un clúster (buena práctica tenerlo aunque sea un solo nodo):
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      # Variables de Confluent para evitar problemas con licencias en versiones de comunidad o desarrollo:
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    networks:
      - dndms_network

  kafdrop: # Cambia el nombre del servicio para reflejar la imagen
    image: obsidiandynamics/kafdrop:latest # Esta es una imagen popular y actualizada
    container_name: kafdrop
    ports:
      - "9000:9000" # Kafdrop usualmente corre en el puerto 9000
    environment:
      KAFKA_BROKERCONNECT: kafka:29092 # 'kafka' es el nombre de tu servicio Kafka en docker-compose
      # JVM_OPTS: "-Xms32M -Xmx64M" # Opcional: para limitar el uso de memoria
    depends_on:
      - kafka
    networks:
      - dndms_network   

  redis:
    image: redis:6.2-alpine
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data # Persistencia para los datos de Redis
    networks:
      - dndms_network

  dynamo-local:
    image: amazon/dynamodb-local:latest
    container_name: dynamo-local
    ports:
      - "8000:8000"
    volumes:
      - dynamodb_data:/home/dynamodblocal/data # Persistencia para los datos de DynamoDB
    command: "-jar DynamoDBLocal.jar -sharedDb -dbPath ./data" # -dbPath es relativo al workdir del contenedor
    networks:
      - dndms_network

  # --- Ejemplo de cómo añadirías tus microservicios más adelante ---
  # dndms-ms1-adventure-forge-app:
  #   # Asume que tienes un Dockerfile en la raíz de este proyecto (dndms-ms1-adventure-forge)
  #   build: . 
  #   container_name: dndms-ms1-adventure-forge-app
  #   ports:
  #     - "8081:8080" # Mapea el puerto 8080 del contenedor al 8081 de tu host
  #   depends_on:
  #     - kafka
  #     - redis
  #     - dynamo-local
  #   environment:
  #     # Perfil de Spring para configuraciones específicas de Docker
  #     SPRING_PROFILES_ACTIVE: docker 
  #     # Configuración para que la aplicación Spring Boot se conecte a Kafka DENTRO de la red Docker
  #     SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka:9092 
  #     SPRING_REDIS_HOST: redis
  #     SPRING_REDIS_PORT: 6379
  #     # Endpoint para DynamoDB Local dentro de la red Docker
  #     AWS_DYNAMODB_ENDPOINT: http://dynamo-local:8000 
  #     AWS_ACCESS_KEY_ID: dummyKeyId # Necesario para el SDK de AWS aunque sea local
  #     AWS_SECRET_ACCESS_KEY: dummySecretKey # Necesario para el SDK de AWS aunque sea local
  #     AWS_REGION: us-east-1 # O cualquier región, para el SDK
  #   networks:
  #     - dndms_network

volumes:
  redis_data: # Define el volumen para persistencia de Redis
  dynamodb_data: # Define el volumen para persistencia de DynamoDB

networks:
  dndms_network: # Define una red personalizada para tus servicios
    driver: bridge