services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - dndms_network

  kafka:
    image: confluentinc/cp-kafka:7.0.1
    container_name: kafka
    ports:
      # Puerto 9092 del contenedor mapeado al 9092 de tu MÁQUINA HOST
      # Esto es para que tu aplicación MS1 corriendo en el HOST (no como contenedor aún) pueda conectarse.
      - "9092:9092"
      # El puerto 29092 NO se expone al host, es solo para comunicación INTERNA entre contenedores.
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      # Define los listeners INTERNOS del broker Kafka dentro de su contenedor:
      KAFKA_LISTENERS: PLAINTEXT_INTERNAL://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      # Define CÓMO se anuncian estos listeners a los clientes:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT_INTERNAL://kafka:29092,PLAINTEXT_HOST://localhost:9092
      # Mapea los nombres de los listeners a protocolos de seguridad:
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT_INTERNAL:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      # Para comunicación entre brokers en un clúster (buena práctica tenerlo aunque sea un solo nodo):
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      # Variables de Confluent para evitar problemas con licencias en versiones de comunidad o desarrollo:
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    networks:
      - dndms_network

  kafdrop: # Cambia el nombre del servicio para reflejar la imagen
    image: obsidiandynamics/kafdrop:latest # Esta es una imagen popular y actualizada
    container_name: kafdrop
    ports:
      - "9000:9000" # Kafdrop usualmente corre en el puerto 9000
    environment:
      KAFKA_BROKERCONNECT: kafka:29092 # 'kafka' es el nombre de tu servicio Kafka en docker-compose
      # JVM_OPTS: "-Xms32M -Xmx64M" # Opcional: para limitar el uso de memoria
    depends_on:
      - kafka
    networks:
      - dndms_network   

  redis:
    image: redis:6.2-alpine
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data # Persistencia para los datos de Redis
    networks:
      - dndms_network

  dynamo-local:
    image: amazon/dynamodb-local:latest
    container_name: dynamo-local
    ports:
      - "8000:8000"
    # command: "-jar DynamoDBLocal.jar -sharedDb -dbPath ./data" 
    command: "-jar DynamoDBLocal.jar -sharedDb -inMemory"
    #volumes:
    #  - dynamodb_data:/home/dynamodblocal/data 
    networks:
      - dndms_network

  # --- AHORA AÑADIMOS NUESTRO MICROSERVICIO ---
  dndms-ms1-adventure-forge-app:
    # 'build: .' le dice a Docker Compose que construya una imagen
    # usando el Dockerfile que se encuentra en el directorio actual.
    build: .
    container_name: dndms-ms1-adventure-forge-app
    ports:
      - "8081:8081" 
    depends_on:
      - kafka
    environment:
      # Perfil de Spring para configuraciones específicas de Docker
      SPRING_PROFILES_ACTIVE: docker 
      # IMPORTANTE: Ahora que MS1 corre DENTRO de la red Docker, debe conectarse a Kafka
      # usando el nombre del servicio 'kafka' y el puerto INTERNO 29092
      # o 'kafka:9092' si usaste la configuración simple para el listener de Kafka.
      #SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka:29092 
    networks:
      - dndms_network

volumes:
  redis_data: # Define el volumen para persistencia de Redis
  dynamodb_data: # Define el volumen para persistencia de DynamoDB

networks:
  dndms_network: # Define una red personalizada para tus servicios
    driver: bridge