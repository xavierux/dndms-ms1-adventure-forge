services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - dndms_network
    healthcheck:
      test: ["CMD", "sh", "-c", "nc -z localhost 2181 || exit 1"] # Comando para verificar si el puerto 2181 está abierto
      interval: 10s # Chequear cada 10 segundos
      timeout: 5s # Dar 5 segundos para que el comando se complete
      retries: 5 # Intentar 5 veces antes de marcar como "unhealthy"
      start_period: 30s # Dar 30 segundos para que el servicio inicie antes de empezar a chequear

  kafka:
    image: confluentinc/cp-kafka:7.0.1
    container_name: kafka
    ports:
      # Puerto 9092 del contenedor mapeado al 9092 de tu MÁQUINA HOST
      # Esto es para que tu aplicación MS1 corriendo en el HOST (no como contenedor aún) pueda conectarse.
      - "9092:9092"
      # El puerto 29092 NO se expone al host, es solo para comunicación INTERNA entre contenedores.
    depends_on:
      zookeeper: # Modificado para esperar el healthcheck
        condition: service_healthy # Espera hasta que zookeeper esté marcado como saludable
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      # Define los listeners INTERNOS del broker Kafka dentro de su contenedor:
      KAFKA_LISTENERS: PLAINTEXT_INTERNAL://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      # Define CÓMO se anuncian estos listeners a los clientes:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT_INTERNAL://kafka:29092,PLAINTEXT_HOST://localhost:9092
      # Mapea los nombres de los listeners a protocolos de seguridad:
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT_INTERNAL:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      # Para comunicación entre brokers en un clúster (buena práctica tenerlo aunque sea un solo nodo):
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      # Variables de Confluent para evitar problemas con licencias en versiones de comunidad o desarrollo:
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    networks:
      - dndms_network
    healthcheck:
      test: ["CMD", "sh", "-c", "nc -z localhost 29092 || exit 1"] # Verifica el puerto interno de Kafka
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 50s # Podría tomar un poco más de tiempo que Zookeeper

  kafdrop: # Cambia el nombre del servicio para reflejar la imagen
    image: obsidiandynamics/kafdrop:latest # Esta es una imagen popular y actualizada
    container_name: kafdrop
    ports:
      - "9000:9000" # Kafdrop usualmente corre en el puerto 9000
    environment:
      KAFKA_BROKERCONNECT: kafka:29092 # 'kafka' es el nombre de tu servicio Kafka en docker-compose
      # JVM_OPTS: "-Xms32M -Xmx64M" # Opcional: para limitar el uso de memoria
    depends_on:
      - kafka
    networks:
      - dndms_network   

  redis:
    image: redis:6.2-alpine
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data # Persistencia para los datos de Redis
    networks:
      - dndms_network

  dynamo-local:
    image: amazon/dynamodb-local:2.4.0
    container_name: dynamo-local
    ports:
      - "8000:8000"
    command: "-jar DynamoDBLocal.jar -sharedDb"          
    networks:
      - dndms_network

  # --- AHORA AÑADIMOS NUESTRO MICROSERVICIO ---
  dndms-ms1-adventure-forge-app:
    # 'build: .' le dice a Docker Compose que construya una imagen
    # usando el Dockerfile que se encuentra en el directorio actual.
    build: .
    container_name: dndms-ms1-adventure-forge-app
    ports:
      - "8081:8081" 
    depends_on:
      kafka:
        condition: service_healthy # Asegúrate de que Kafka esté saludable
    environment:
      # Perfil de Spring para configuraciones específicas de Docker
      SPRING_PROFILES_ACTIVE: docker 
      # IMPORTANTE: Ahora que MS1 corre DENTRO de la red Docker, debe conectarse a Kafka
      # usando el nombre del servicio 'kafka' y el puerto INTERNO 29092
      # o 'kafka:9092' si usaste la configuración simple para el listener de Kafka.
      #SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka:29092 
    networks:
      - dndms_network
    
  dndms-ms2-character-roster-app:
    build:
      # ¡IMPORTANTE! La ruta al contexto de build es relativa al docker-compose.yml
      context: ../dndms-ms2-character-roster 
    container_name: dndms-ms2-character-roster-app
    ports:
      # Mapea el puerto 8082 del contenedor al 8082 de tu host
      - "8082:8082" 
    depends_on:
      kafka:
        condition: service_healthy # Asegúrate de que Kafka esté saludable
      dynamo-local:
        condition: service_started # No hay healthcheck para DynamoDB, así que 'service_started' es suficiente
    environment:
      # Activa el perfil de Spring 'docker' para que lea application-docker.properties
      SPRING_PROFILES_ACTIVE: docker
      AWS_ACCESS_KEY_ID: 'test'
      AWS_SECRET_ACCESS_KEY: 'test'
      AWS_REGION: 'us-east-1'
    networks:
      - dndms_network

  dndms-ms3-combat-arena-app:
    build:
      context: ../dndms-ms3-combat-arena
    container_name: dndms-ms3-combat-arena-app
    ports:
      - "8083:8083"
    depends_on:
      kafka:
        condition: service_healthy
      dynamo-local:
        condition: service_started
      dndms-ms2-character-roster-app:
        condition: service_started
    environment:
      SPRING_PROFILES_ACTIVE: docker
      AWS_ACCESS_KEY_ID: test-key
      AWS_SECRET_ACCESS_KEY: test-secret
      AWS_REGION: us-east-1
    networks:
      - dndms_network

volumes:
  redis_data: # Define el volumen para persistencia de Redis
  dynamodb_data: # Define el volumen para persistencia de DynamoDB

networks:
  dndms_network: # Define una red personalizada para tus servicios
    driver: bridge